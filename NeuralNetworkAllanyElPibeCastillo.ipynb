{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import os\n",
    "import tempfile\n",
    "import matplotlib as mpl\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Karpathy 1. fix random seed\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATT_FILE_NAME = \"FootballPlayerPreparedCleanAttributes.csv\"\n",
    "ONE_HOT_ENCODED_CLASSES_FILE_NAME = \"FootballPlayerOneHotEncodedClasses.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = pd.read_csv(ATT_FILE_NAME)\n",
    "target = pd.read_csv(ONE_HOT_ENCODED_CLASSES_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crossing</th>\n",
       "      <th>HeadingAccuracy</th>\n",
       "      <th>ShortPassing</th>\n",
       "      <th>Volleys</th>\n",
       "      <th>Dribbling</th>\n",
       "      <th>Curve</th>\n",
       "      <th>FKAccuracy</th>\n",
       "      <th>LongPassing</th>\n",
       "      <th>BallControl</th>\n",
       "      <th>Reactions</th>\n",
       "      <th>ShotPower</th>\n",
       "      <th>Stamina</th>\n",
       "      <th>LongShots</th>\n",
       "      <th>Aggression</th>\n",
       "      <th>Positioning</th>\n",
       "      <th>Vision</th>\n",
       "      <th>Composure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16122.000000</td>\n",
       "      <td>16122.000000</td>\n",
       "      <td>16122.000000</td>\n",
       "      <td>16122.000000</td>\n",
       "      <td>16122.000000</td>\n",
       "      <td>16122.000000</td>\n",
       "      <td>16122.000000</td>\n",
       "      <td>16122.000000</td>\n",
       "      <td>16122.000000</td>\n",
       "      <td>16122.000000</td>\n",
       "      <td>16122.000000</td>\n",
       "      <td>16122.000000</td>\n",
       "      <td>16122.000000</td>\n",
       "      <td>16122.000000</td>\n",
       "      <td>16122.000000</td>\n",
       "      <td>16122.000000</td>\n",
       "      <td>16122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.053537</td>\n",
       "      <td>0.064942</td>\n",
       "      <td>0.168294</td>\n",
       "      <td>-0.081373</td>\n",
       "      <td>0.122654</td>\n",
       "      <td>-0.030012</td>\n",
       "      <td>-0.132537</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.076091</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.125965</td>\n",
       "      <td>0.169170</td>\n",
       "      <td>-0.025506</td>\n",
       "      <td>0.136145</td>\n",
       "      <td>0.043417</td>\n",
       "      <td>0.060219</td>\n",
       "      <td>0.036497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.344606</td>\n",
       "      <td>0.293820</td>\n",
       "      <td>0.268085</td>\n",
       "      <td>0.369549</td>\n",
       "      <td>0.301492</td>\n",
       "      <td>0.364944</td>\n",
       "      <td>0.358826</td>\n",
       "      <td>0.334822</td>\n",
       "      <td>0.282066</td>\n",
       "      <td>0.233806</td>\n",
       "      <td>0.326638</td>\n",
       "      <td>0.324097</td>\n",
       "      <td>0.379027</td>\n",
       "      <td>0.352347</td>\n",
       "      <td>0.349409</td>\n",
       "      <td>0.314939</td>\n",
       "      <td>0.274291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.195122</td>\n",
       "      <td>-0.139241</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.012048</td>\n",
       "      <td>-0.325301</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>-0.189189</td>\n",
       "      <td>-0.070423</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>-0.086420</td>\n",
       "      <td>-0.014493</td>\n",
       "      <td>-0.301205</td>\n",
       "      <td>-0.097561</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.146341</td>\n",
       "      <td>-0.162162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>0.205479</td>\n",
       "      <td>-0.075000</td>\n",
       "      <td>0.180723</td>\n",
       "      <td>-0.012048</td>\n",
       "      <td>-0.190476</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.098592</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.160494</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.054054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.265823</td>\n",
       "      <td>0.342466</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.325301</td>\n",
       "      <td>0.253012</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.267606</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.277108</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.243243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Crossing  HeadingAccuracy  ShortPassing       Volleys  \\\n",
       "count  16122.000000     16122.000000  16122.000000  16122.000000   \n",
       "mean       0.053537         0.064942      0.168294     -0.081373   \n",
       "std        0.344606         0.293820      0.268085      0.369549   \n",
       "min       -1.000000        -1.000000     -1.000000     -1.000000   \n",
       "25%       -0.195122        -0.139241      0.013699     -0.375000   \n",
       "50%        0.097561         0.088608      0.205479     -0.075000   \n",
       "75%        0.317073         0.265823      0.342466      0.200000   \n",
       "max        1.000000         1.000000      1.000000      1.000000   \n",
       "\n",
       "          Dribbling         Curve    FKAccuracy   LongPassing   BallControl  \\\n",
       "count  16122.000000  16122.000000  16122.000000  16122.000000  16122.000000   \n",
       "mean       0.122654     -0.030012     -0.132537      0.002751      0.076091   \n",
       "std        0.301492      0.364944      0.358826      0.334822      0.282066   \n",
       "min       -1.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "25%       -0.012048     -0.325301     -0.428571     -0.189189     -0.070423   \n",
       "50%        0.180723     -0.012048     -0.190476      0.054054      0.098592   \n",
       "75%        0.325301      0.253012      0.142857      0.243243      0.267606   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          Reactions     ShotPower       Stamina     LongShots    Aggression  \\\n",
       "count  16122.000000  16122.000000  16122.000000  16122.000000  16122.000000   \n",
       "mean       0.098800      0.125965      0.169170     -0.025506      0.136145   \n",
       "std        0.233806      0.326638      0.324097      0.379027      0.352347   \n",
       "min       -1.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "25%       -0.066667     -0.086420     -0.014493     -0.301205     -0.097561   \n",
       "50%        0.093333      0.160494      0.188406      0.036145      0.170732   \n",
       "75%        0.253333      0.358025      0.391304      0.277108      0.390244   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        Positioning        Vision     Composure  \n",
       "count  16122.000000  16122.000000  16122.000000  \n",
       "mean       0.043417      0.060219      0.036497  \n",
       "std        0.349409      0.314939      0.274291  \n",
       "min       -1.000000     -1.000000     -1.000000  \n",
       "25%       -0.166667     -0.146341     -0.162162  \n",
       "50%        0.095238      0.097561      0.054054  \n",
       "75%        0.285714      0.292683      0.243243  \n",
       "max        1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Poor:[46.0, 62.0]</th>\n",
       "      <th>Interm:[63.0, 66.0]</th>\n",
       "      <th>Good:[67.0, 71.0]</th>\n",
       "      <th>Excel:[72.0, 94.0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Poor:[46.0, 62.0]  Interm:[63.0, 66.0]  Good:[67.0, 71.0]  \\\n",
       "0                0.0                  1.0                0.0   \n",
       "1                0.0                  0.0                1.0   \n",
       "2                1.0                  0.0                0.0   \n",
       "3                0.0                  0.0                1.0   \n",
       "4                0.0                  1.0                0.0   \n",
       "\n",
       "   Excel:[72.0, 94.0]  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clases = np.argmax(target.to_numpy(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4296, 3868, 4353, 3605], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(clases) # contar cuantos elemntos tengo de cada clase en el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 16122. C1 4296, c2 3868, c3 4353, c4 3605\n"
     ]
    }
   ],
   "source": [
    "c1, c2,c3,c4= np.bincount(clases)\n",
    "total = c1+c2+c3+c4\n",
    "print(f\"Total: {total}. C1 {c1}, c2 {c2}, c3 {c3}, c4 {c4}\") #lo mismo de arriba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_rem,y_train,y_rem = train_test_split(att,target,train_size=0.8)\n",
    "X_valid,X_test,y_valid,y_test = train_test_split(X_rem,y_rem,train_size=0.5)\n",
    "#80 % train   --- 10% val 10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 12897. C1 3455, c2 3086, c3 3479, c4 2877\n"
     ]
    }
   ],
   "source": [
    "c1, c2,c3,c4= np.bincount(np.argmax(y_train.to_numpy(),axis=1))\n",
    "total = c1+c2+c3+c4\n",
    "print(f\"Total: {total}. C1 {c1}, c2 {c2}, c3 {c3}, c4 {c4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "  if output_bias is not None:\n",
    "    output_bias = tf.keras.initializers.Constant(output_bias) # inicializar el bias de la ultima capa de manera sesgada para que todas las clases sean \"casi\" iguales\n",
    "  model = keras.Sequential([\n",
    "      keras.layers.Dense(\n",
    "          16, activation='relu',\n",
    "          input_shape=(17,)),\n",
    "      keras.layers.Dropout(0.5),\n",
    "      keras.layers.Dense(4, activation='sigmoid',\n",
    "                         bias_initializer=output_bias),\n",
    "  ])\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=metrics)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_prc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-math.log(1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_train,y_train,batch_size=BATCH_SIZE)\n",
    "print(f\"Loss: {results[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = [c1/total,c2/total,c3/total,c4/total]\n",
    "frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi = np.log(frequency)\n",
    "bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve\n",
    "from math import exp\n",
    "def eqn(x, frequency=frequency):\n",
    "  sum_exp = sum([exp(x_i) for x_i in x])\n",
    "  return [exp(x[i])/sum_exp - frequency[i] for i in range(len(frequency))]\n",
    "\n",
    "# calculate bias init\n",
    "bias_init = fsolve(func=eqn,\n",
    "                  x0=[0]*len(frequency),\n",
    "                  ).tolist()\n",
    "\n",
    "bias_init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(output_bias=bias_init)\n",
    "model.evaluate(X_train,y_train,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "model.load_weights(initial_weights)\n",
    "model.layers[-1].bias.assign([0.0,0.0,0.0,0.0])\n",
    "zero_bias_history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=20,\n",
    "    validation_data=(X_test, y_test), \n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(output_bias=bias_init)\n",
    "model.load_weights(initial_weights)\n",
    "careful_bias_history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=20,\n",
    "    validation_data=(X_test, y_test), \n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, label, n):\n",
    "  # Use a log scale on y-axis to show the wide range of values.\n",
    "  plt.semilogy(history.epoch, history.history['loss'],\n",
    "               color=colors[n], label='Train ' + label)\n",
    "  plt.semilogy(history.epoch, history.history['val_loss'],\n",
    "               color=colors[n], label='Val ' + label,\n",
    "               linestyle=\"--\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'zero_bias_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19440/351470068.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero_bias_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Zero Bias\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplot_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcareful_bias_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Careful Bias\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'zero_bias_history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_loss(zero_bias_history, \"Zero Bias\", 0)\n",
    "plot_loss(careful_bias_history, \"Careful Bias\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'careful_bias_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19440/2730548498.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcareful_bias_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'careful_bias_history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_metrics(careful_bias_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BATCH_SIZE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19440/290388698.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_predictions_baseline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_predictions_baseline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BATCH_SIZE' is not defined"
     ]
    }
   ],
   "source": [
    "train_predictions_baseline = model.predict(X_train, batch_size=BATCH_SIZE)\n",
    "test_predictions_baseline = model.predict(X_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels,predictions)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix')\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = model.evaluate(X_test, y_test,\n",
    "                                  batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(np.argmax(y_test.to_numpy(),axis=1), test_predictions_baseline.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generación de un modelo simple con un perceptron de una capa y pocas neuronas para conocer un poco donde estamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando 1 capa y pocas neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando dos capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que a mas capas, mejores resultados. Verificación utilizando muchas neuronas por capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados mejores. Probamos con aún más neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadir más neuronas auemnta el tiempo de entrenamiento ligeramente (CPU only) sin dar mejores resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo ahora es conseguir un modelo lo bastante grande que haga overfit a los datos y reducirlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la precisión no parece estancarse lo dejamos durante muchas mas epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos el overfit del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h_100x4x100.history['val_categorical_accuracy'])\n",
    "plt.plot(h_100x4x100.history['categorical_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['val_accuracy','train_accuracy'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos estrategias de regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(17,)),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "model.summary()\n",
    "h_100x4x100= model.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiene buana pinta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(17,)),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "model.summary()\n",
    "h_100x4x100= model.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadir una capa mas no aporta nada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(17,)),\n",
    "    \n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dropout(0.25),\n",
    "\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dropout(0.25),\n",
    "\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "model.summary()\n",
    "h_100x4x100= model.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h_128128.history['val_categorical_accuracy'])\n",
    "plt.plot(h_nocapas.history['val_categorical_accuracy'])\n",
    "plt.plot(h_512512.history['val_categorical_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['h28128', 'nocapas','512512'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons_ocultas=[30], learning_rate=3e-3, input_shape=(8,), \n",
    "                activation_o=\"relu\", optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=METRICS, \n",
    "                activation_s=\"soft_max\", n_neurons_salida=4):     \n",
    "    model = keras.models.Sequential()     \n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    if n_hidden != len(n_neurons_ocultas):\n",
    "        print(\"error, tamaño de la lista de n_neuronas no corresponde al umero de capas\")\n",
    "        return -1\n",
    "    for layer in range(n_hidden):         \n",
    "        model.add(keras.layers.Dense(n_neurons_ocultas[layer], activation=\"relu\"))     \n",
    "  \n",
    "    model.add(keras.layers.Dense(n_neurons_salida, activation=activation_s))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)     \n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=metrics)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 30)                540       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 20)                620       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 4)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,244\n",
      "Trainable params: 1,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 2s 14ms/step - loss: 0.9000 - tp: 5812.0000 - fp: 1750.0000 - tn: 41780.0000 - fn: 8698.0000 - accuracy: 0.8200 - precision: 0.7686 - recall: 0.4006 - auc: 0.8725 - prc: 0.7106 - val_loss: 0.7576 - val_tp: 906.0000 - val_fp: 407.0000 - val_tn: 4432.0000 - val_fn: 707.0000 - val_accuracy: 0.8273 - val_precision: 0.6900 - val_recall: 0.5617 - val_auc: 0.8947 - val_prc: 0.7489\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.6644 - tp: 8216.0000 - fp: 3167.0000 - tn: 35524.0000 - fn: 4681.0000 - accuracy: 0.8479 - precision: 0.7218 - recall: 0.6370 - auc: 0.9167 - prc: 0.7850 - val_loss: 0.5629 - val_tp: 1159.0000 - val_fp: 318.0000 - val_tn: 4521.0000 - val_fn: 454.0000 - val_accuracy: 0.8803 - val_precision: 0.7847 - val_recall: 0.7185 - val_auc: 0.9429 - val_prc: 0.8510\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.5964 - tp: 9143.0000 - fp: 3107.0000 - tn: 35584.0000 - fn: 3754.0000 - accuracy: 0.8670 - precision: 0.7464 - recall: 0.7089 - auc: 0.9326 - prc: 0.8208 - val_loss: 0.5516 - val_tp: 1199.0000 - val_fp: 361.0000 - val_tn: 4478.0000 - val_fn: 414.0000 - val_accuracy: 0.8799 - val_precision: 0.7686 - val_recall: 0.7433 - val_auc: 0.9432 - val_prc: 0.8522\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.5502 - tp: 9522.0000 - fp: 3041.0000 - tn: 35650.0000 - fn: 3375.0000 - accuracy: 0.8756 - precision: 0.7579 - recall: 0.7383 - auc: 0.9418 - prc: 0.8438 - val_loss: 0.6245 - val_tp: 1104.0000 - val_fp: 423.0000 - val_tn: 4416.0000 - val_fn: 509.0000 - val_accuracy: 0.8555 - val_precision: 0.7230 - val_recall: 0.6844 - val_auc: 0.9263 - val_prc: 0.8104\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.5222 - tp: 9762.0000 - fp: 2844.0000 - tn: 35847.0000 - fn: 3135.0000 - accuracy: 0.8841 - precision: 0.7744 - recall: 0.7569 - auc: 0.9478 - prc: 0.8591 - val_loss: 0.5291 - val_tp: 1215.0000 - val_fp: 372.0000 - val_tn: 4467.0000 - val_fn: 398.0000 - val_accuracy: 0.8807 - val_precision: 0.7656 - val_recall: 0.7533 - val_auc: 0.9465 - val_prc: 0.8560\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.5202 - tp: 9818.0000 - fp: 2884.0000 - tn: 35807.0000 - fn: 3079.0000 - accuracy: 0.8844 - precision: 0.7729 - recall: 0.7613 - auc: 0.9479 - prc: 0.8590 - val_loss: 0.5096 - val_tp: 1253.0000 - val_fp: 336.0000 - val_tn: 4503.0000 - val_fn: 360.0000 - val_accuracy: 0.8921 - val_precision: 0.7885 - val_recall: 0.7768 - val_auc: 0.9509 - val_prc: 0.8690\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.5108 - tp: 9879.0000 - fp: 2823.0000 - tn: 35868.0000 - fn: 3018.0000 - accuracy: 0.8868 - precision: 0.7778 - recall: 0.7660 - auc: 0.9493 - prc: 0.8614 - val_loss: 0.5943 - val_tp: 1171.0000 - val_fp: 430.0000 - val_tn: 4409.0000 - val_fn: 442.0000 - val_accuracy: 0.8648 - val_precision: 0.7314 - val_recall: 0.7260 - val_auc: 0.9337 - val_prc: 0.8202\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4870 - tp: 10016.0000 - fp: 2733.0000 - tn: 35958.0000 - fn: 2881.0000 - accuracy: 0.8912 - precision: 0.7856 - recall: 0.7766 - auc: 0.9543 - prc: 0.8754 - val_loss: 0.4946 - val_tp: 1243.0000 - val_fp: 356.0000 - val_tn: 4483.0000 - val_fn: 370.0000 - val_accuracy: 0.8875 - val_precision: 0.7774 - val_recall: 0.7706 - val_auc: 0.9527 - val_prc: 0.8718\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4664 - tp: 10189.0000 - fp: 2575.0000 - tn: 36116.0000 - fn: 2708.0000 - accuracy: 0.8976 - precision: 0.7983 - recall: 0.7900 - auc: 0.9580 - prc: 0.8851 - val_loss: 0.4492 - val_tp: 1288.0000 - val_fp: 313.0000 - val_tn: 4526.0000 - val_fn: 325.0000 - val_accuracy: 0.9011 - val_precision: 0.8045 - val_recall: 0.7985 - val_auc: 0.9617 - val_prc: 0.8961\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4860 - tp: 10083.0000 - fp: 2689.0000 - tn: 36002.0000 - fn: 2814.0000 - accuracy: 0.8933 - precision: 0.7895 - recall: 0.7818 - auc: 0.9544 - prc: 0.8760 - val_loss: 0.4691 - val_tp: 1266.0000 - val_fp: 327.0000 - val_tn: 4512.0000 - val_fn: 347.0000 - val_accuracy: 0.8955 - val_precision: 0.7947 - val_recall: 0.7849 - val_auc: 0.9577 - val_prc: 0.8857\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4659 - tp: 10195.0000 - fp: 2581.0000 - tn: 36110.0000 - fn: 2702.0000 - accuracy: 0.8976 - precision: 0.7980 - recall: 0.7905 - auc: 0.9580 - prc: 0.8851 - val_loss: 0.4724 - val_tp: 1269.0000 - val_fp: 330.0000 - val_tn: 4509.0000 - val_fn: 344.0000 - val_accuracy: 0.8955 - val_precision: 0.7936 - val_recall: 0.7867 - val_auc: 0.9571 - val_prc: 0.8837\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4641 - tp: 10176.0000 - fp: 2570.0000 - tn: 36121.0000 - fn: 2721.0000 - accuracy: 0.8974 - precision: 0.7984 - recall: 0.7890 - auc: 0.9585 - prc: 0.8865 - val_loss: 0.4461 - val_tp: 1286.0000 - val_fp: 318.0000 - val_tn: 4521.0000 - val_fn: 327.0000 - val_accuracy: 0.9000 - val_precision: 0.8017 - val_recall: 0.7973 - val_auc: 0.9619 - val_prc: 0.8967\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4648 - tp: 10137.0000 - fp: 2651.0000 - tn: 36040.0000 - fn: 2760.0000 - accuracy: 0.8951 - precision: 0.7927 - recall: 0.7860 - auc: 0.9581 - prc: 0.8854 - val_loss: 0.6209 - val_tp: 1136.0000 - val_fp: 446.0000 - val_tn: 4393.0000 - val_fn: 477.0000 - val_accuracy: 0.8569 - val_precision: 0.7181 - val_recall: 0.7043 - val_auc: 0.9314 - val_prc: 0.8198\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4738 - tp: 10138.0000 - fp: 2628.0000 - tn: 36063.0000 - fn: 2759.0000 - accuracy: 0.8956 - precision: 0.7941 - recall: 0.7861 - auc: 0.9566 - prc: 0.8807 - val_loss: 0.4313 - val_tp: 1295.0000 - val_fp: 304.0000 - val_tn: 4535.0000 - val_fn: 318.0000 - val_accuracy: 0.9036 - val_precision: 0.8099 - val_recall: 0.8029 - val_auc: 0.9646 - val_prc: 0.9041\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4625 - tp: 10220.0000 - fp: 2575.0000 - tn: 36116.0000 - fn: 2677.0000 - accuracy: 0.8982 - precision: 0.7987 - recall: 0.7924 - auc: 0.9587 - prc: 0.8867 - val_loss: 0.4736 - val_tp: 1274.0000 - val_fp: 331.0000 - val_tn: 4508.0000 - val_fn: 339.0000 - val_accuracy: 0.8962 - val_precision: 0.7938 - val_recall: 0.7898 - val_auc: 0.9572 - val_prc: 0.8836\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4654 - tp: 10195.0000 - fp: 2582.0000 - tn: 36109.0000 - fn: 2702.0000 - accuracy: 0.8976 - precision: 0.7979 - recall: 0.7905 - auc: 0.9583 - prc: 0.8861 - val_loss: 0.4858 - val_tp: 1265.0000 - val_fp: 340.0000 - val_tn: 4499.0000 - val_fn: 348.0000 - val_accuracy: 0.8934 - val_precision: 0.7882 - val_recall: 0.7843 - val_auc: 0.9544 - val_prc: 0.8733\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4457 - tp: 10315.0000 - fp: 2475.0000 - tn: 36216.0000 - fn: 2582.0000 - accuracy: 0.9020 - precision: 0.8065 - recall: 0.7998 - auc: 0.9615 - prc: 0.8944 - val_loss: 0.4637 - val_tp: 1277.0000 - val_fp: 319.0000 - val_tn: 4520.0000 - val_fn: 336.0000 - val_accuracy: 0.8985 - val_precision: 0.8001 - val_recall: 0.7917 - val_auc: 0.9590 - val_prc: 0.8886\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4510 - tp: 10282.0000 - fp: 2510.0000 - tn: 36181.0000 - fn: 2615.0000 - accuracy: 0.9007 - precision: 0.8038 - recall: 0.7972 - auc: 0.9606 - prc: 0.8921 - val_loss: 0.4872 - val_tp: 1263.0000 - val_fp: 339.0000 - val_tn: 4500.0000 - val_fn: 350.0000 - val_accuracy: 0.8932 - val_precision: 0.7884 - val_recall: 0.7830 - val_auc: 0.9544 - val_prc: 0.8743\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4493 - tp: 10309.0000 - fp: 2495.0000 - tn: 36196.0000 - fn: 2588.0000 - accuracy: 0.9015 - precision: 0.8051 - recall: 0.7993 - auc: 0.9610 - prc: 0.8929 - val_loss: 0.6805 - val_tp: 1088.0000 - val_fp: 499.0000 - val_tn: 4340.0000 - val_fn: 525.0000 - val_accuracy: 0.8413 - val_precision: 0.6856 - val_recall: 0.6745 - val_auc: 0.9230 - val_prc: 0.8014\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4562 - tp: 10226.0000 - fp: 2562.0000 - tn: 36129.0000 - fn: 2671.0000 - accuracy: 0.8986 - precision: 0.7997 - recall: 0.7929 - auc: 0.9595 - prc: 0.8890 - val_loss: 0.5231 - val_tp: 1225.0000 - val_fp: 385.0000 - val_tn: 4454.0000 - val_fn: 388.0000 - val_accuracy: 0.8802 - val_precision: 0.7609 - val_recall: 0.7595 - val_auc: 0.9477 - val_prc: 0.8564\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4538 - tp: 10269.0000 - fp: 2519.0000 - tn: 36172.0000 - fn: 2628.0000 - accuracy: 0.9002 - precision: 0.8030 - recall: 0.7962 - auc: 0.9602 - prc: 0.8906 - val_loss: 0.4330 - val_tp: 1296.0000 - val_fp: 309.0000 - val_tn: 4530.0000 - val_fn: 317.0000 - val_accuracy: 0.9030 - val_precision: 0.8075 - val_recall: 0.8035 - val_auc: 0.9640 - val_prc: 0.9026\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4537 - tp: 10289.0000 - fp: 2496.0000 - tn: 36195.0000 - fn: 2608.0000 - accuracy: 0.9011 - precision: 0.8048 - recall: 0.7978 - auc: 0.9603 - prc: 0.8912 - val_loss: 0.4874 - val_tp: 1253.0000 - val_fp: 346.0000 - val_tn: 4493.0000 - val_fn: 360.0000 - val_accuracy: 0.8906 - val_precision: 0.7836 - val_recall: 0.7768 - val_auc: 0.9536 - val_prc: 0.8724\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4558 - tp: 10230.0000 - fp: 2559.0000 - tn: 36132.0000 - fn: 2667.0000 - accuracy: 0.8987 - precision: 0.7999 - recall: 0.7932 - auc: 0.9596 - prc: 0.8896 - val_loss: 0.5506 - val_tp: 1210.0000 - val_fp: 397.0000 - val_tn: 4442.0000 - val_fn: 403.0000 - val_accuracy: 0.8760 - val_precision: 0.7530 - val_recall: 0.7502 - val_auc: 0.9449 - val_prc: 0.8513\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4492 - tp: 10284.0000 - fp: 2514.0000 - tn: 36177.0000 - fn: 2613.0000 - accuracy: 0.9006 - precision: 0.8036 - recall: 0.7974 - auc: 0.9608 - prc: 0.8921 - val_loss: 0.4632 - val_tp: 1281.0000 - val_fp: 317.0000 - val_tn: 4522.0000 - val_fn: 332.0000 - val_accuracy: 0.8994 - val_precision: 0.8016 - val_recall: 0.7942 - val_auc: 0.9588 - val_prc: 0.8879\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4392 - tp: 10375.0000 - fp: 2419.0000 - tn: 36272.0000 - fn: 2522.0000 - accuracy: 0.9042 - precision: 0.8109 - recall: 0.8045 - auc: 0.9627 - prc: 0.8974 - val_loss: 0.4465 - val_tp: 1282.0000 - val_fp: 315.0000 - val_tn: 4524.0000 - val_fn: 331.0000 - val_accuracy: 0.8999 - val_precision: 0.8028 - val_recall: 0.7948 - val_auc: 0.9616 - val_prc: 0.8953\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4414 - tp: 10352.0000 - fp: 2423.0000 - tn: 36268.0000 - fn: 2545.0000 - accuracy: 0.9037 - precision: 0.8103 - recall: 0.8027 - auc: 0.9623 - prc: 0.8963 - val_loss: 0.4551 - val_tp: 1283.0000 - val_fp: 312.0000 - val_tn: 4527.0000 - val_fn: 330.0000 - val_accuracy: 0.9005 - val_precision: 0.8044 - val_recall: 0.7954 - val_auc: 0.9599 - val_prc: 0.8906\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4374 - tp: 10390.0000 - fp: 2410.0000 - tn: 36281.0000 - fn: 2507.0000 - accuracy: 0.9047 - precision: 0.8117 - recall: 0.8056 - auc: 0.9630 - prc: 0.8981 - val_loss: 0.4368 - val_tp: 1289.0000 - val_fp: 295.0000 - val_tn: 4544.0000 - val_fn: 324.0000 - val_accuracy: 0.9041 - val_precision: 0.8138 - val_recall: 0.7991 - val_auc: 0.9632 - val_prc: 0.9000\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4427 - tp: 10326.0000 - fp: 2475.0000 - tn: 36216.0000 - fn: 2571.0000 - accuracy: 0.9022 - precision: 0.8067 - recall: 0.8007 - auc: 0.9620 - prc: 0.8953 - val_loss: 0.4322 - val_tp: 1300.0000 - val_fp: 297.0000 - val_tn: 4542.0000 - val_fn: 313.0000 - val_accuracy: 0.9055 - val_precision: 0.8140 - val_recall: 0.8060 - val_auc: 0.9640 - val_prc: 0.9020\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4434 - tp: 10347.0000 - fp: 2442.0000 - tn: 36249.0000 - fn: 2550.0000 - accuracy: 0.9032 - precision: 0.8091 - recall: 0.8023 - auc: 0.9620 - prc: 0.8954 - val_loss: 0.4188 - val_tp: 1305.0000 - val_fp: 287.0000 - val_tn: 4552.0000 - val_fn: 308.0000 - val_accuracy: 0.9078 - val_precision: 0.8197 - val_recall: 0.8091 - val_auc: 0.9663 - val_prc: 0.9090\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4354 - tp: 10419.0000 - fp: 2394.0000 - tn: 36297.0000 - fn: 2478.0000 - accuracy: 0.9056 - precision: 0.8132 - recall: 0.8079 - auc: 0.9632 - prc: 0.8988 - val_loss: 0.4344 - val_tp: 1299.0000 - val_fp: 305.0000 - val_tn: 4534.0000 - val_fn: 314.0000 - val_accuracy: 0.9041 - val_precision: 0.8099 - val_recall: 0.8053 - val_auc: 0.9636 - val_prc: 0.9007\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4391 - tp: 10371.0000 - fp: 2432.0000 - tn: 36259.0000 - fn: 2526.0000 - accuracy: 0.9039 - precision: 0.8100 - recall: 0.8041 - auc: 0.9626 - prc: 0.8970 - val_loss: 0.4246 - val_tp: 1296.0000 - val_fp: 298.0000 - val_tn: 4541.0000 - val_fn: 317.0000 - val_accuracy: 0.9047 - val_precision: 0.8130 - val_recall: 0.8035 - val_auc: 0.9656 - val_prc: 0.9066\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4362 - tp: 10391.0000 - fp: 2411.0000 - tn: 36280.0000 - fn: 2506.0000 - accuracy: 0.9047 - precision: 0.8117 - recall: 0.8057 - auc: 0.9630 - prc: 0.8980 - val_loss: 0.4875 - val_tp: 1257.0000 - val_fp: 350.0000 - val_tn: 4489.0000 - val_fn: 356.0000 - val_accuracy: 0.8906 - val_precision: 0.7822 - val_recall: 0.7793 - val_auc: 0.9545 - val_prc: 0.8755\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4297 - tp: 10394.0000 - fp: 2408.0000 - tn: 36283.0000 - fn: 2503.0000 - accuracy: 0.9048 - precision: 0.8119 - recall: 0.8059 - auc: 0.9641 - prc: 0.9011 - val_loss: 0.4257 - val_tp: 1308.0000 - val_fp: 283.0000 - val_tn: 4556.0000 - val_fn: 305.0000 - val_accuracy: 0.9089 - val_precision: 0.8221 - val_recall: 0.8109 - val_auc: 0.9652 - val_prc: 0.9047\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4291 - tp: 10434.0000 - fp: 2374.0000 - tn: 36317.0000 - fn: 2463.0000 - accuracy: 0.9062 - precision: 0.8146 - recall: 0.8090 - auc: 0.9644 - prc: 0.9019 - val_loss: 0.4346 - val_tp: 1296.0000 - val_fp: 297.0000 - val_tn: 4542.0000 - val_fn: 317.0000 - val_accuracy: 0.9048 - val_precision: 0.8136 - val_recall: 0.8035 - val_auc: 0.9636 - val_prc: 0.9013\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4482 - tp: 10323.0000 - fp: 2472.0000 - tn: 36219.0000 - fn: 2574.0000 - accuracy: 0.9022 - precision: 0.8068 - recall: 0.8004 - auc: 0.9611 - prc: 0.8929 - val_loss: 0.4331 - val_tp: 1288.0000 - val_fp: 308.0000 - val_tn: 4531.0000 - val_fn: 325.0000 - val_accuracy: 0.9019 - val_precision: 0.8070 - val_recall: 0.7985 - val_auc: 0.9634 - val_prc: 0.8997\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4276 - tp: 10446.0000 - fp: 2370.0000 - tn: 36321.0000 - fn: 2451.0000 - accuracy: 0.9065 - precision: 0.8151 - recall: 0.8100 - auc: 0.9646 - prc: 0.9026 - val_loss: 0.4244 - val_tp: 1301.0000 - val_fp: 298.0000 - val_tn: 4541.0000 - val_fn: 312.0000 - val_accuracy: 0.9055 - val_precision: 0.8136 - val_recall: 0.8066 - val_auc: 0.9652 - val_prc: 0.9050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4299 - tp: 10415.0000 - fp: 2395.0000 - tn: 36296.0000 - fn: 2482.0000 - accuracy: 0.9055 - precision: 0.8130 - recall: 0.8076 - auc: 0.9640 - prc: 0.9006 - val_loss: 0.4366 - val_tp: 1286.0000 - val_fp: 312.0000 - val_tn: 4527.0000 - val_fn: 327.0000 - val_accuracy: 0.9010 - val_precision: 0.8048 - val_recall: 0.7973 - val_auc: 0.9629 - val_prc: 0.8988\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4354 - tp: 10394.0000 - fp: 2432.0000 - tn: 36259.0000 - fn: 2503.0000 - accuracy: 0.9043 - precision: 0.8104 - recall: 0.8059 - auc: 0.9631 - prc: 0.8984 - val_loss: 0.4630 - val_tp: 1271.0000 - val_fp: 332.0000 - val_tn: 4507.0000 - val_fn: 342.0000 - val_accuracy: 0.8955 - val_precision: 0.7929 - val_recall: 0.7880 - val_auc: 0.9585 - val_prc: 0.8860\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4266 - tp: 10457.0000 - fp: 2354.0000 - tn: 36337.0000 - fn: 2440.0000 - accuracy: 0.9071 - precision: 0.8163 - recall: 0.8108 - auc: 0.9647 - prc: 0.9026 - val_loss: 0.4166 - val_tp: 1308.0000 - val_fp: 292.0000 - val_tn: 4547.0000 - val_fn: 305.0000 - val_accuracy: 0.9075 - val_precision: 0.8175 - val_recall: 0.8109 - val_auc: 0.9667 - val_prc: 0.9101\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4137 - tp: 10524.0000 - fp: 2286.0000 - tn: 36405.0000 - fn: 2373.0000 - accuracy: 0.9097 - precision: 0.8215 - recall: 0.8160 - auc: 0.9668 - prc: 0.9086 - val_loss: 0.4361 - val_tp: 1302.0000 - val_fp: 294.0000 - val_tn: 4545.0000 - val_fn: 311.0000 - val_accuracy: 0.9062 - val_precision: 0.8158 - val_recall: 0.8072 - val_auc: 0.9633 - val_prc: 0.9005\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4226 - tp: 10502.0000 - fp: 2327.0000 - tn: 36364.0000 - fn: 2395.0000 - accuracy: 0.9085 - precision: 0.8186 - recall: 0.8143 - auc: 0.9654 - prc: 0.9046 - val_loss: 0.4712 - val_tp: 1277.0000 - val_fp: 319.0000 - val_tn: 4520.0000 - val_fn: 336.0000 - val_accuracy: 0.8985 - val_precision: 0.8001 - val_recall: 0.7917 - val_auc: 0.9577 - val_prc: 0.8858\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4202 - tp: 10495.0000 - fp: 2317.0000 - tn: 36374.0000 - fn: 2402.0000 - accuracy: 0.9085 - precision: 0.8192 - recall: 0.8138 - auc: 0.9657 - prc: 0.9056 - val_loss: 0.4631 - val_tp: 1281.0000 - val_fp: 322.0000 - val_tn: 4517.0000 - val_fn: 332.0000 - val_accuracy: 0.8986 - val_precision: 0.7991 - val_recall: 0.7942 - val_auc: 0.9589 - val_prc: 0.8895\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4292 - tp: 10443.0000 - fp: 2365.0000 - tn: 36326.0000 - fn: 2454.0000 - accuracy: 0.9066 - precision: 0.8153 - recall: 0.8097 - auc: 0.9642 - prc: 0.9011 - val_loss: 0.4269 - val_tp: 1303.0000 - val_fp: 294.0000 - val_tn: 4545.0000 - val_fn: 310.0000 - val_accuracy: 0.9064 - val_precision: 0.8159 - val_recall: 0.8078 - val_auc: 0.9648 - val_prc: 0.9041\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4283 - tp: 10455.0000 - fp: 2340.0000 - tn: 36351.0000 - fn: 2442.0000 - accuracy: 0.9073 - precision: 0.8171 - recall: 0.8107 - auc: 0.9644 - prc: 0.9020 - val_loss: 0.7674 - val_tp: 1084.0000 - val_fp: 518.0000 - val_tn: 4321.0000 - val_fn: 529.0000 - val_accuracy: 0.8377 - val_precision: 0.6767 - val_recall: 0.6720 - val_auc: 0.9085 - val_prc: 0.7660\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4305 - tp: 10450.0000 - fp: 2346.0000 - tn: 36345.0000 - fn: 2447.0000 - accuracy: 0.9071 - precision: 0.8167 - recall: 0.8103 - auc: 0.9640 - prc: 0.9008 - val_loss: 0.4263 - val_tp: 1296.0000 - val_fp: 305.0000 - val_tn: 4534.0000 - val_fn: 317.0000 - val_accuracy: 0.9036 - val_precision: 0.8095 - val_recall: 0.8035 - val_auc: 0.9649 - val_prc: 0.9042\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4259 - tp: 10498.0000 - fp: 2314.0000 - tn: 36377.0000 - fn: 2399.0000 - accuracy: 0.9086 - precision: 0.8194 - recall: 0.8140 - auc: 0.9648 - prc: 0.9029 - val_loss: 0.4396 - val_tp: 1288.0000 - val_fp: 309.0000 - val_tn: 4530.0000 - val_fn: 325.0000 - val_accuracy: 0.9017 - val_precision: 0.8065 - val_recall: 0.7985 - val_auc: 0.9629 - val_prc: 0.8992\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4148 - tp: 10554.0000 - fp: 2270.0000 - tn: 36421.0000 - fn: 2343.0000 - accuracy: 0.9106 - precision: 0.8230 - recall: 0.8183 - auc: 0.9666 - prc: 0.9076 - val_loss: 0.5611 - val_tp: 1216.0000 - val_fp: 391.0000 - val_tn: 4448.0000 - val_fn: 397.0000 - val_accuracy: 0.8779 - val_precision: 0.7567 - val_recall: 0.7539 - val_auc: 0.9435 - val_prc: 0.8468\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4311 - tp: 10408.0000 - fp: 2404.0000 - tn: 36287.0000 - fn: 2489.0000 - accuracy: 0.9052 - precision: 0.8124 - recall: 0.8070 - auc: 0.9639 - prc: 0.9007 - val_loss: 0.5063 - val_tp: 1246.0000 - val_fp: 362.0000 - val_tn: 4477.0000 - val_fn: 367.0000 - val_accuracy: 0.8870 - val_precision: 0.7749 - val_recall: 0.7725 - val_auc: 0.9517 - val_prc: 0.8700\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4219 - tp: 10491.0000 - fp: 2320.0000 - tn: 36371.0000 - fn: 2406.0000 - accuracy: 0.9084 - precision: 0.8189 - recall: 0.8134 - auc: 0.9653 - prc: 0.9043 - val_loss: 0.4764 - val_tp: 1252.0000 - val_fp: 351.0000 - val_tn: 4488.0000 - val_fn: 361.0000 - val_accuracy: 0.8896 - val_precision: 0.7810 - val_recall: 0.7762 - val_auc: 0.9567 - val_prc: 0.8825\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4193 - tp: 10491.0000 - fp: 2319.0000 - tn: 36372.0000 - fn: 2406.0000 - accuracy: 0.9084 - precision: 0.8190 - recall: 0.8134 - auc: 0.9659 - prc: 0.9058 - val_loss: 0.4252 - val_tp: 1291.0000 - val_fp: 296.0000 - val_tn: 4543.0000 - val_fn: 322.0000 - val_accuracy: 0.9042 - val_precision: 0.8135 - val_recall: 0.8004 - val_auc: 0.9648 - val_prc: 0.9046\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4191 - tp: 10512.0000 - fp: 2307.0000 - tn: 36384.0000 - fn: 2385.0000 - accuracy: 0.9090 - precision: 0.8200 - recall: 0.8151 - auc: 0.9659 - prc: 0.9060 - val_loss: 0.4209 - val_tp: 1312.0000 - val_fp: 284.0000 - val_tn: 4555.0000 - val_fn: 301.0000 - val_accuracy: 0.9093 - val_precision: 0.8221 - val_recall: 0.8134 - val_auc: 0.9659 - val_prc: 0.9077\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4111 - tp: 10537.0000 - fp: 2276.0000 - tn: 36415.0000 - fn: 2360.0000 - accuracy: 0.9101 - precision: 0.8224 - recall: 0.8170 - auc: 0.9672 - prc: 0.9093 - val_loss: 0.4249 - val_tp: 1309.0000 - val_fp: 291.0000 - val_tn: 4548.0000 - val_fn: 304.0000 - val_accuracy: 0.9078 - val_precision: 0.8181 - val_recall: 0.8115 - val_auc: 0.9650 - val_prc: 0.9041\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4240 - tp: 10486.0000 - fp: 2328.0000 - tn: 36363.0000 - fn: 2411.0000 - accuracy: 0.9081 - precision: 0.8183 - recall: 0.8131 - auc: 0.9651 - prc: 0.9038 - val_loss: 0.4902 - val_tp: 1272.0000 - val_fp: 336.0000 - val_tn: 4503.0000 - val_fn: 341.0000 - val_accuracy: 0.8951 - val_precision: 0.7910 - val_recall: 0.7886 - val_auc: 0.9547 - val_prc: 0.8798\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4161 - tp: 10502.0000 - fp: 2321.0000 - tn: 36370.0000 - fn: 2395.0000 - accuracy: 0.9086 - precision: 0.8190 - recall: 0.8143 - auc: 0.9664 - prc: 0.9073 - val_loss: 0.4581 - val_tp: 1281.0000 - val_fp: 309.0000 - val_tn: 4530.0000 - val_fn: 332.0000 - val_accuracy: 0.9007 - val_precision: 0.8057 - val_recall: 0.7942 - val_auc: 0.9599 - val_prc: 0.8913\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4128 - tp: 10549.0000 - fp: 2246.0000 - tn: 36445.0000 - fn: 2348.0000 - accuracy: 0.9109 - precision: 0.8245 - recall: 0.8179 - auc: 0.9669 - prc: 0.9086 - val_loss: 0.4371 - val_tp: 1293.0000 - val_fp: 309.0000 - val_tn: 4530.0000 - val_fn: 320.0000 - val_accuracy: 0.9025 - val_precision: 0.8071 - val_recall: 0.8016 - val_auc: 0.9632 - val_prc: 0.8995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4237 - tp: 10467.0000 - fp: 2352.0000 - tn: 36339.0000 - fn: 2430.0000 - accuracy: 0.9073 - precision: 0.8165 - recall: 0.8116 - auc: 0.9651 - prc: 0.9037 - val_loss: 0.4511 - val_tp: 1283.0000 - val_fp: 310.0000 - val_tn: 4529.0000 - val_fn: 330.0000 - val_accuracy: 0.9008 - val_precision: 0.8054 - val_recall: 0.7954 - val_auc: 0.9615 - val_prc: 0.8954\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4135 - tp: 10534.0000 - fp: 2276.0000 - tn: 36415.0000 - fn: 2363.0000 - accuracy: 0.9101 - precision: 0.8223 - recall: 0.8168 - auc: 0.9668 - prc: 0.9084 - val_loss: 0.4221 - val_tp: 1321.0000 - val_fp: 281.0000 - val_tn: 4558.0000 - val_fn: 292.0000 - val_accuracy: 0.9112 - val_precision: 0.8246 - val_recall: 0.8190 - val_auc: 0.9657 - val_prc: 0.9059\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4134 - tp: 10549.0000 - fp: 2272.0000 - tn: 36419.0000 - fn: 2348.0000 - accuracy: 0.9104 - precision: 0.8228 - recall: 0.8179 - auc: 0.9667 - prc: 0.9079 - val_loss: 0.4159 - val_tp: 1313.0000 - val_fp: 291.0000 - val_tn: 4548.0000 - val_fn: 300.0000 - val_accuracy: 0.9084 - val_precision: 0.8186 - val_recall: 0.8140 - val_auc: 0.9667 - val_prc: 0.9093\n",
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4221 - tp: 10508.0000 - fp: 2314.0000 - tn: 36377.0000 - fn: 2389.0000 - accuracy: 0.9088 - precision: 0.8195 - recall: 0.8148 - auc: 0.9654 - prc: 0.9045 - val_loss: 0.5057 - val_tp: 1262.0000 - val_fp: 338.0000 - val_tn: 4501.0000 - val_fn: 351.0000 - val_accuracy: 0.8932 - val_precision: 0.7887 - val_recall: 0.7824 - val_auc: 0.9533 - val_prc: 0.8776\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4215 - tp: 10490.0000 - fp: 2311.0000 - tn: 36380.0000 - fn: 2407.0000 - accuracy: 0.9085 - precision: 0.8195 - recall: 0.8134 - auc: 0.9655 - prc: 0.9053 - val_loss: 0.4363 - val_tp: 1315.0000 - val_fp: 286.0000 - val_tn: 4553.0000 - val_fn: 298.0000 - val_accuracy: 0.9095 - val_precision: 0.8214 - val_recall: 0.8153 - val_auc: 0.9637 - val_prc: 0.9020\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4075 - tp: 10553.0000 - fp: 2252.0000 - tn: 36439.0000 - fn: 2344.0000 - accuracy: 0.9109 - precision: 0.8241 - recall: 0.8183 - auc: 0.9677 - prc: 0.9109 - val_loss: 0.4714 - val_tp: 1287.0000 - val_fp: 316.0000 - val_tn: 4523.0000 - val_fn: 326.0000 - val_accuracy: 0.9005 - val_precision: 0.8029 - val_recall: 0.7979 - val_auc: 0.9585 - val_prc: 0.8889\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4073 - tp: 10593.0000 - fp: 2229.0000 - tn: 36462.0000 - fn: 2304.0000 - accuracy: 0.9121 - precision: 0.8262 - recall: 0.8214 - auc: 0.9678 - prc: 0.9114 - val_loss: 0.4401 - val_tp: 1290.0000 - val_fp: 309.0000 - val_tn: 4530.0000 - val_fn: 323.0000 - val_accuracy: 0.9020 - val_precision: 0.8068 - val_recall: 0.7998 - val_auc: 0.9622 - val_prc: 0.8967\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4192 - tp: 10503.0000 - fp: 2312.0000 - tn: 36379.0000 - fn: 2394.0000 - accuracy: 0.9088 - precision: 0.8196 - recall: 0.8144 - auc: 0.9659 - prc: 0.9057 - val_loss: 0.4709 - val_tp: 1274.0000 - val_fp: 322.0000 - val_tn: 4517.0000 - val_fn: 339.0000 - val_accuracy: 0.8976 - val_precision: 0.7982 - val_recall: 0.7898 - val_auc: 0.9580 - val_prc: 0.8868\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4087 - tp: 10573.0000 - fp: 2242.0000 - tn: 36449.0000 - fn: 2324.0000 - accuracy: 0.9115 - precision: 0.8250 - recall: 0.8198 - auc: 0.9677 - prc: 0.9105 - val_loss: 0.5213 - val_tp: 1244.0000 - val_fp: 358.0000 - val_tn: 4481.0000 - val_fn: 369.0000 - val_accuracy: 0.8873 - val_precision: 0.7765 - val_recall: 0.7712 - val_auc: 0.9504 - val_prc: 0.8641\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4071 - tp: 10566.0000 - fp: 2249.0000 - tn: 36442.0000 - fn: 2331.0000 - accuracy: 0.9112 - precision: 0.8245 - recall: 0.8193 - auc: 0.9677 - prc: 0.9111 - val_loss: 0.5316 - val_tp: 1236.0000 - val_fp: 369.0000 - val_tn: 4470.0000 - val_fn: 377.0000 - val_accuracy: 0.8844 - val_precision: 0.7701 - val_recall: 0.7663 - val_auc: 0.9476 - val_prc: 0.8541\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4152 - tp: 10506.0000 - fp: 2313.0000 - tn: 36378.0000 - fn: 2391.0000 - accuracy: 0.9088 - precision: 0.8196 - recall: 0.8146 - auc: 0.9665 - prc: 0.9075 - val_loss: 0.4912 - val_tp: 1256.0000 - val_fp: 340.0000 - val_tn: 4499.0000 - val_fn: 357.0000 - val_accuracy: 0.8920 - val_precision: 0.7870 - val_recall: 0.7787 - val_auc: 0.9542 - val_prc: 0.8758\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4071 - tp: 10581.0000 - fp: 2236.0000 - tn: 36455.0000 - fn: 2316.0000 - accuracy: 0.9118 - precision: 0.8255 - recall: 0.8204 - auc: 0.9678 - prc: 0.9112 - val_loss: 0.4346 - val_tp: 1310.0000 - val_fp: 296.0000 - val_tn: 4543.0000 - val_fn: 303.0000 - val_accuracy: 0.9072 - val_precision: 0.8157 - val_recall: 0.8122 - val_auc: 0.9634 - val_prc: 0.8999\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4067 - tp: 10584.0000 - fp: 2230.0000 - tn: 36461.0000 - fn: 2313.0000 - accuracy: 0.9119 - precision: 0.8260 - recall: 0.8207 - auc: 0.9679 - prc: 0.9113 - val_loss: 0.4731 - val_tp: 1280.0000 - val_fp: 320.0000 - val_tn: 4519.0000 - val_fn: 333.0000 - val_accuracy: 0.8988 - val_precision: 0.8000 - val_recall: 0.7936 - val_auc: 0.9586 - val_prc: 0.8873\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4077 - tp: 10585.0000 - fp: 2237.0000 - tn: 36454.0000 - fn: 2312.0000 - accuracy: 0.9118 - precision: 0.8255 - recall: 0.8207 - auc: 0.9675 - prc: 0.9103 - val_loss: 0.4642 - val_tp: 1267.0000 - val_fp: 333.0000 - val_tn: 4506.0000 - val_fn: 346.0000 - val_accuracy: 0.8948 - val_precision: 0.7919 - val_recall: 0.7855 - val_auc: 0.9593 - val_prc: 0.8895\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4057 - tp: 10579.0000 - fp: 2246.0000 - tn: 36445.0000 - fn: 2318.0000 - accuracy: 0.9115 - precision: 0.8249 - recall: 0.8203 - auc: 0.9679 - prc: 0.9115 - val_loss: 0.4428 - val_tp: 1316.0000 - val_fp: 285.0000 - val_tn: 4554.0000 - val_fn: 297.0000 - val_accuracy: 0.9098 - val_precision: 0.8220 - val_recall: 0.8159 - val_auc: 0.9624 - val_prc: 0.8991\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4012 - tp: 10583.0000 - fp: 2222.0000 - tn: 36469.0000 - fn: 2314.0000 - accuracy: 0.9121 - precision: 0.8265 - recall: 0.8206 - auc: 0.9688 - prc: 0.9139 - val_loss: 0.4603 - val_tp: 1277.0000 - val_fp: 330.0000 - val_tn: 4509.0000 - val_fn: 336.0000 - val_accuracy: 0.8968 - val_precision: 0.7946 - val_recall: 0.7917 - val_auc: 0.9595 - val_prc: 0.8898\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4042 - tp: 10597.0000 - fp: 2211.0000 - tn: 36480.0000 - fn: 2300.0000 - accuracy: 0.9126 - precision: 0.8274 - recall: 0.8217 - auc: 0.9684 - prc: 0.9128 - val_loss: 0.4495 - val_tp: 1295.0000 - val_fp: 311.0000 - val_tn: 4528.0000 - val_fn: 318.0000 - val_accuracy: 0.9025 - val_precision: 0.8064 - val_recall: 0.8029 - val_auc: 0.9609 - val_prc: 0.8927\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4033 - tp: 10579.0000 - fp: 2248.0000 - tn: 36443.0000 - fn: 2318.0000 - accuracy: 0.9115 - precision: 0.8247 - recall: 0.8203 - auc: 0.9684 - prc: 0.9125 - val_loss: 0.4166 - val_tp: 1315.0000 - val_fp: 287.0000 - val_tn: 4552.0000 - val_fn: 298.0000 - val_accuracy: 0.9093 - val_precision: 0.8208 - val_recall: 0.8153 - val_auc: 0.9666 - val_prc: 0.9094\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4172 - tp: 10534.0000 - fp: 2283.0000 - tn: 36408.0000 - fn: 2363.0000 - accuracy: 0.9099 - precision: 0.8219 - recall: 0.8168 - auc: 0.9661 - prc: 0.9064 - val_loss: 0.4214 - val_tp: 1318.0000 - val_fp: 282.0000 - val_tn: 4557.0000 - val_fn: 295.0000 - val_accuracy: 0.9106 - val_precision: 0.8238 - val_recall: 0.8171 - val_auc: 0.9657 - val_prc: 0.9062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4045 - tp: 10592.0000 - fp: 2244.0000 - tn: 36447.0000 - fn: 2305.0000 - accuracy: 0.9118 - precision: 0.8252 - recall: 0.8213 - auc: 0.9682 - prc: 0.9125 - val_loss: 0.4401 - val_tp: 1292.0000 - val_fp: 308.0000 - val_tn: 4531.0000 - val_fn: 321.0000 - val_accuracy: 0.9025 - val_precision: 0.8075 - val_recall: 0.8010 - val_auc: 0.9630 - val_prc: 0.8990\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3998 - tp: 10619.0000 - fp: 2204.0000 - tn: 36487.0000 - fn: 2278.0000 - accuracy: 0.9131 - precision: 0.8281 - recall: 0.8234 - auc: 0.9689 - prc: 0.9140 - val_loss: 0.4165 - val_tp: 1326.0000 - val_fp: 281.0000 - val_tn: 4558.0000 - val_fn: 287.0000 - val_accuracy: 0.9120 - val_precision: 0.8251 - val_recall: 0.8221 - val_auc: 0.9668 - val_prc: 0.9100\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4033 - tp: 10614.0000 - fp: 2221.0000 - tn: 36470.0000 - fn: 2283.0000 - accuracy: 0.9127 - precision: 0.8270 - recall: 0.8230 - auc: 0.9684 - prc: 0.9126 - val_loss: 0.4726 - val_tp: 1275.0000 - val_fp: 332.0000 - val_tn: 4507.0000 - val_fn: 338.0000 - val_accuracy: 0.8962 - val_precision: 0.7934 - val_recall: 0.7905 - val_auc: 0.9575 - val_prc: 0.8849\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4077 - tp: 10597.0000 - fp: 2225.0000 - tn: 36466.0000 - fn: 2300.0000 - accuracy: 0.9123 - precision: 0.8265 - recall: 0.8217 - auc: 0.9677 - prc: 0.9108 - val_loss: 0.4484 - val_tp: 1296.0000 - val_fp: 308.0000 - val_tn: 4531.0000 - val_fn: 317.0000 - val_accuracy: 0.9031 - val_precision: 0.8080 - val_recall: 0.8035 - val_auc: 0.9615 - val_prc: 0.8969\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4029 - tp: 10621.0000 - fp: 2204.0000 - tn: 36487.0000 - fn: 2276.0000 - accuracy: 0.9132 - precision: 0.8281 - recall: 0.8235 - auc: 0.9684 - prc: 0.9130 - val_loss: 0.4597 - val_tp: 1290.0000 - val_fp: 319.0000 - val_tn: 4520.0000 - val_fn: 323.0000 - val_accuracy: 0.9005 - val_precision: 0.8017 - val_recall: 0.7998 - val_auc: 0.9589 - val_prc: 0.8859\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4086 - tp: 10575.0000 - fp: 2259.0000 - tn: 36432.0000 - fn: 2322.0000 - accuracy: 0.9112 - precision: 0.8240 - recall: 0.8200 - auc: 0.9675 - prc: 0.9101 - val_loss: 0.4379 - val_tp: 1311.0000 - val_fp: 291.0000 - val_tn: 4548.0000 - val_fn: 302.0000 - val_accuracy: 0.9081 - val_precision: 0.8184 - val_recall: 0.8128 - val_auc: 0.9636 - val_prc: 0.9014\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4060 - tp: 10618.0000 - fp: 2190.0000 - tn: 36501.0000 - fn: 2279.0000 - accuracy: 0.9134 - precision: 0.8290 - recall: 0.8233 - auc: 0.9680 - prc: 0.9118 - val_loss: 0.4290 - val_tp: 1312.0000 - val_fp: 294.0000 - val_tn: 4545.0000 - val_fn: 301.0000 - val_accuracy: 0.9078 - val_precision: 0.8169 - val_recall: 0.8134 - val_auc: 0.9647 - val_prc: 0.9037\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4019 - tp: 10611.0000 - fp: 2220.0000 - tn: 36471.0000 - fn: 2286.0000 - accuracy: 0.9127 - precision: 0.8270 - recall: 0.8227 - auc: 0.9686 - prc: 0.9132 - val_loss: 0.4279 - val_tp: 1306.0000 - val_fp: 286.0000 - val_tn: 4553.0000 - val_fn: 307.0000 - val_accuracy: 0.9081 - val_precision: 0.8204 - val_recall: 0.8097 - val_auc: 0.9648 - val_prc: 0.9037\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 0.4037 - tp: 10588.0000 - fp: 2243.0000 - tn: 36448.0000 - fn: 2309.0000 - accuracy: 0.9118 - precision: 0.8252 - recall: 0.8210 - auc: 0.9683 - prc: 0.9125 - val_loss: 0.4188 - val_tp: 1317.0000 - val_fp: 285.0000 - val_tn: 4554.0000 - val_fn: 296.0000 - val_accuracy: 0.9100 - val_precision: 0.8221 - val_recall: 0.8165 - val_auc: 0.9665 - val_prc: 0.9084\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3987 - tp: 10637.0000 - fp: 2175.0000 - tn: 36516.0000 - fn: 2260.0000 - accuracy: 0.9140 - precision: 0.8302 - recall: 0.8248 - auc: 0.9691 - prc: 0.9145 - val_loss: 0.4366 - val_tp: 1294.0000 - val_fp: 312.0000 - val_tn: 4527.0000 - val_fn: 319.0000 - val_accuracy: 0.9022 - val_precision: 0.8057 - val_recall: 0.8022 - val_auc: 0.9633 - val_prc: 0.8996\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4057 - tp: 10607.0000 - fp: 2211.0000 - tn: 36480.0000 - fn: 2290.0000 - accuracy: 0.9128 - precision: 0.8275 - recall: 0.8224 - auc: 0.9680 - prc: 0.9116 - val_loss: 0.4225 - val_tp: 1313.0000 - val_fp: 292.0000 - val_tn: 4547.0000 - val_fn: 300.0000 - val_accuracy: 0.9082 - val_precision: 0.8181 - val_recall: 0.8140 - val_auc: 0.9656 - val_prc: 0.9064\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3953 - tp: 10656.0000 - fp: 2184.0000 - tn: 36507.0000 - fn: 2241.0000 - accuracy: 0.9142 - precision: 0.8299 - recall: 0.8262 - auc: 0.9697 - prc: 0.9162 - val_loss: 0.5510 - val_tp: 1226.0000 - val_fp: 377.0000 - val_tn: 4462.0000 - val_fn: 387.0000 - val_accuracy: 0.8816 - val_precision: 0.7648 - val_recall: 0.7601 - val_auc: 0.9469 - val_prc: 0.8587\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4030 - tp: 10606.0000 - fp: 2216.0000 - tn: 36475.0000 - fn: 2291.0000 - accuracy: 0.9126 - precision: 0.8272 - recall: 0.8224 - auc: 0.9684 - prc: 0.9126 - val_loss: 0.4178 - val_tp: 1315.0000 - val_fp: 285.0000 - val_tn: 4554.0000 - val_fn: 298.0000 - val_accuracy: 0.9096 - val_precision: 0.8219 - val_recall: 0.8153 - val_auc: 0.9662 - val_prc: 0.9085\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4056 - tp: 10586.0000 - fp: 2237.0000 - tn: 36454.0000 - fn: 2311.0000 - accuracy: 0.9118 - precision: 0.8255 - recall: 0.8208 - auc: 0.9679 - prc: 0.9112 - val_loss: 0.4286 - val_tp: 1300.0000 - val_fp: 301.0000 - val_tn: 4538.0000 - val_fn: 313.0000 - val_accuracy: 0.9048 - val_precision: 0.8120 - val_recall: 0.8060 - val_auc: 0.9649 - val_prc: 0.9040\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3979 - tp: 10606.0000 - fp: 2234.0000 - tn: 36457.0000 - fn: 2291.0000 - accuracy: 0.9123 - precision: 0.8260 - recall: 0.8224 - auc: 0.9692 - prc: 0.9151 - val_loss: 0.4422 - val_tp: 1298.0000 - val_fp: 308.0000 - val_tn: 4531.0000 - val_fn: 315.0000 - val_accuracy: 0.9034 - val_precision: 0.8082 - val_recall: 0.8047 - val_auc: 0.9620 - val_prc: 0.8956\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4046 - tp: 10583.0000 - fp: 2232.0000 - tn: 36459.0000 - fn: 2314.0000 - accuracy: 0.9119 - precision: 0.8258 - recall: 0.8206 - auc: 0.9681 - prc: 0.9118 - val_loss: 0.4239 - val_tp: 1294.0000 - val_fp: 300.0000 - val_tn: 4539.0000 - val_fn: 319.0000 - val_accuracy: 0.9041 - val_precision: 0.8118 - val_recall: 0.8022 - val_auc: 0.9653 - val_prc: 0.9057\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3992 - tp: 10615.0000 - fp: 2206.0000 - tn: 36485.0000 - fn: 2282.0000 - accuracy: 0.9130 - precision: 0.8279 - recall: 0.8231 - auc: 0.9689 - prc: 0.9144 - val_loss: 0.4543 - val_tp: 1291.0000 - val_fp: 312.0000 - val_tn: 4527.0000 - val_fn: 322.0000 - val_accuracy: 0.9017 - val_precision: 0.8054 - val_recall: 0.8004 - val_auc: 0.9604 - val_prc: 0.8918\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3971 - tp: 10639.0000 - fp: 2174.0000 - tn: 36517.0000 - fn: 2258.0000 - accuracy: 0.9141 - precision: 0.8303 - recall: 0.8249 - auc: 0.9693 - prc: 0.9154 - val_loss: 0.4324 - val_tp: 1309.0000 - val_fp: 293.0000 - val_tn: 4546.0000 - val_fn: 304.0000 - val_accuracy: 0.9075 - val_precision: 0.8171 - val_recall: 0.8115 - val_auc: 0.9643 - val_prc: 0.9032\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3951 - tp: 10655.0000 - fp: 2168.0000 - tn: 36523.0000 - fn: 2242.0000 - accuracy: 0.9145 - precision: 0.8309 - recall: 0.8262 - auc: 0.9696 - prc: 0.9163 - val_loss: 0.4265 - val_tp: 1320.0000 - val_fp: 284.0000 - val_tn: 4555.0000 - val_fn: 293.0000 - val_accuracy: 0.9106 - val_precision: 0.8229 - val_recall: 0.8184 - val_auc: 0.9648 - val_prc: 0.9036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.4031 - tp: 10594.0000 - fp: 2235.0000 - tn: 36456.0000 - fn: 2303.0000 - accuracy: 0.9120 - precision: 0.8258 - recall: 0.8214 - auc: 0.9683 - prc: 0.9127 - val_loss: 0.4199 - val_tp: 1316.0000 - val_fp: 286.0000 - val_tn: 4553.0000 - val_fn: 297.0000 - val_accuracy: 0.9096 - val_precision: 0.8215 - val_recall: 0.8159 - val_auc: 0.9659 - val_prc: 0.9071\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3995 - tp: 10614.0000 - fp: 2201.0000 - tn: 36490.0000 - fn: 2283.0000 - accuracy: 0.9131 - precision: 0.8282 - recall: 0.8230 - auc: 0.9690 - prc: 0.9143 - val_loss: 0.5126 - val_tp: 1257.0000 - val_fp: 336.0000 - val_tn: 4503.0000 - val_fn: 356.0000 - val_accuracy: 0.8927 - val_precision: 0.7891 - val_recall: 0.7793 - val_auc: 0.9529 - val_prc: 0.8751\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3971 - tp: 10646.0000 - fp: 2193.0000 - tn: 36498.0000 - fn: 2251.0000 - accuracy: 0.9139 - precision: 0.8292 - recall: 0.8255 - auc: 0.9693 - prc: 0.9152 - val_loss: 0.4287 - val_tp: 1305.0000 - val_fp: 302.0000 - val_tn: 4537.0000 - val_fn: 308.0000 - val_accuracy: 0.9055 - val_precision: 0.8121 - val_recall: 0.8091 - val_auc: 0.9645 - val_prc: 0.9025\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3940 - tp: 10635.0000 - fp: 2187.0000 - tn: 36504.0000 - fn: 2262.0000 - accuracy: 0.9138 - precision: 0.8294 - recall: 0.8246 - auc: 0.9698 - prc: 0.9164 - val_loss: 0.5233 - val_tp: 1247.0000 - val_fp: 363.0000 - val_tn: 4476.0000 - val_fn: 366.0000 - val_accuracy: 0.8870 - val_precision: 0.7745 - val_recall: 0.7731 - val_auc: 0.9504 - val_prc: 0.8635\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3957 - tp: 10655.0000 - fp: 2176.0000 - tn: 36515.0000 - fn: 2242.0000 - accuracy: 0.9144 - precision: 0.8304 - recall: 0.8262 - auc: 0.9695 - prc: 0.9160 - val_loss: 0.4177 - val_tp: 1307.0000 - val_fp: 290.0000 - val_tn: 4549.0000 - val_fn: 306.0000 - val_accuracy: 0.9076 - val_precision: 0.8184 - val_recall: 0.8103 - val_auc: 0.9661 - val_prc: 0.9075\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3979 - tp: 10608.0000 - fp: 2229.0000 - tn: 36462.0000 - fn: 2289.0000 - accuracy: 0.9124 - precision: 0.8264 - recall: 0.8225 - auc: 0.9692 - prc: 0.9148 - val_loss: 0.4225 - val_tp: 1321.0000 - val_fp: 286.0000 - val_tn: 4553.0000 - val_fn: 292.0000 - val_accuracy: 0.9104 - val_precision: 0.8220 - val_recall: 0.8190 - val_auc: 0.9659 - val_prc: 0.9063\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.3966 - tp: 10648.0000 - fp: 2189.0000 - tn: 36502.0000 - fn: 2249.0000 - accuracy: 0.9140 - precision: 0.8295 - recall: 0.8256 - auc: 0.9693 - prc: 0.9149 - val_loss: 0.4909 - val_tp: 1282.0000 - val_fp: 321.0000 - val_tn: 4518.0000 - val_fn: 331.0000 - val_accuracy: 0.8989 - val_precision: 0.7998 - val_recall: 0.7948 - val_auc: 0.9558 - val_prc: 0.8826\n",
      "51/51 [==============================] - 0s 940us/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "loss :  0.4909203350543976\n",
      "tp :  1282.0\n",
      "fp :  321.0\n",
      "tn :  4518.0\n",
      "fn :  331.0\n",
      "accuracy :  0.8989460468292236\n",
      "precision :  0.7997504472732544\n",
      "recall :  0.7947922945022583\n",
      "auc :  0.9558188915252686\n",
      "prc :  0.8825627565383911\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model(2, [30,20], 0.5, (17,), \"relu\", \"adam\", \"categorical_crossentropy\", METRICS, \"softmax\", 4)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "h_100x4x100= model.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test), batch_size=256)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_predictions_baseline = model.predict(X_train, batch_size=256)\n",
    "test_predictions_baseline = model.predict(X_test, batch_size=256)\n",
    "\n",
    "\n",
    "plot_metrics(h_100x4x100)\n",
    "\n",
    "baseline_results = model.evaluate(X_test, y_test,\n",
    "                                  batch_size=256, verbose=0)\n",
    "for name, value in zip(model.metrics_names, baseline_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(np.argmax(y_test.to_numpy(),axis=1), test_predictions_baseline.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IGNORAR NLP CON TORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cadenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = []\n",
    "for x,y in zip(cadenas,cadenas_target):\n",
    "\n",
    "\n",
    "    misdatos  = {}\n",
    "    misdatos['label'] = y\n",
    "    misdatos['text'] = x\n",
    "    datos.append(misdatos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=np.reshape(cadenas,(-1,1)),columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = np.reshape(cadenas_target,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "ds = Dataset.from_pandas(df)\n",
    "ds = ds.with_format('torch')\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.train_test_split(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds['train'],\n",
    "    eval_dataset=ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8863d0c6094564aaeb41a5a3a6a2d4ce9faecc1a6add5ccddbb72eef631d0103"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
